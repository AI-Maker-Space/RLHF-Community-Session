{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/PanoEvJ/summarization_RLHF/blob/main/rlhf_PPO.ipynb",
      "authorship_tag": "ABX9TyNdrXqKi99C/17Qjrc2EuHO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PanoEvJ/summarization_RLHF/blob/main/rlhf_PPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AguXQuvcFKvF",
        "outputId": "1090863c-3dbd-4bff-cb88-88c6ff0b2ccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for trl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.8/188.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.8/218.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U git+https://github.com/lvwerra/trl.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "\n",
        "!pip install -q transformers==4.30\n",
        "!pip install -q -U sentencepiece\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -q tdqm torch>=0.3.0\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import wandb\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset as TorchDataset\n",
        "from datasets import load_dataset, Dataset\n",
        "from peft import (AutoPeftModelForCausalLM,\n",
        "                  LoraConfig,\n",
        "                  PeftConfig,\n",
        "                  PeftModel,\n",
        "                  TaskType\n",
        ")\n",
        "from tqdm import tqdm\n",
        "from transformers import (AutoModelForSeq2SeqLM,\n",
        "                          AutoModelForSequenceClassification,\n",
        "                          AutoTokenizer,\n",
        "                          BitsAndBytesConfig,\n",
        "                          TrainingArguments,\n",
        "                          AutoTokenizer,\n",
        "                          T5ForConditionalGeneration,\n",
        "                          T5Tokenizer\n",
        ")\n",
        "from trl import (SFTTrainer,\n",
        "                 PPOConfig,\n",
        "                 PPOTrainer,\n",
        "                 AutoModelForSeq2SeqLMWithValueHead,\n",
        "                 create_reference_model,\n",
        "                 set_seed\n",
        ")\n",
        "from trl.core import LengthSampler"
      ],
      "metadata": {
        "id": "Mo3XpkZaFSfj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import get_dataset_split_names\n",
        "\n",
        "dataset_name = 'CarperAI/openai_summarize_comparisons'\n",
        "get_dataset_split_names(dataset_name)\n",
        "\n",
        "dataset = load_dataset('CarperAI/openai_summarize_comparisons', split='train').shuffle(seed=42)\n",
        "ppo_dataset = Dataset(dataset['prompt'])"
      ],
      "metadata": {
        "id": "mA_cTCdZP0Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "id": "SQii6BmGQG1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_8bit=True,\n",
        "#     bnb_8bit_use_double_quant=True,\n",
        "#     bnb_8bit_quant_type=\"nf8\",\n",
        "#     bnb_8bit_compute_dtype=torch.bfloat16,\n",
        "# )"
      ],
      "metadata": {
        "id": "QUI2BjQ-Isoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    # target_modules=[\"q\", \"k\", \"v\"],\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_2_SEQ_LM\",\n",
        "    inference_mode=False,\n",
        ")"
      ],
      "metadata": {
        "id": "kLL_8LRGR_VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_model_id = 't5-base'\n",
        "policy_model_id = 'PanoEvJ/T5_base_SFT_summarization'\n",
        "\n",
        "ref_model = AutoModelForSeq2SeqLM.from_pretrained(ref_model_id,\n",
        "                                                  device_map=\"auto\",\n",
        "                                                  load_in_8bit=True,\n",
        "                                                  # quantization_config=bnb_config,\n",
        "                                                 )\n",
        "policy_model = AutoModelForSeq2SeqLM.from_pretrained(policy_model_id,\n",
        "                                                     device_map=\"auto\",\n",
        "                                                     load_in_8bit=True,\n",
        "                                                    #  quantization_config=bnb_config,\n",
        "                                                    #  peft_config=peft_config\n",
        "                                                    )"
      ],
      "metadata": {
        "id": "0Yl3IfaEGKxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# policy_model = PeftModel(policy_model, peft_config)"
      ],
      "metadata": {
        "id": "PFZyYRUyXMkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see the available modules by printint out the model\n",
        "print(policy_model)"
      ],
      "metadata": {
        "id": "3OzDbykkTlwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )\n",
        "\n",
        "print_trainable_parameters(ref_model)"
      ],
      "metadata": {
        "id": "Nq_wmkUaTR7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(ref_model_id,\n",
        "                                          model_max_length=512,\n",
        "                                          truncation=True,\n",
        "                                          padding=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "E9U89qiTV8xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reward_model = AutoModelForSequenceClassification.from_pretrained(\"JuanKO/rlhf\")\n",
        "reward_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "zzJwKp4zRZMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_config = PPOConfig(\n",
        "    steps=512,\n",
        "    model_name=policy_model,\n",
        "    learning_rate=1e-4,\n",
        "    batch_size=128,\n",
        "    mini_batch_size=16,\n",
        "    gradient_accumulation_steps=1,\n",
        "    optimize_cuda_cache=True,\n",
        "    ppo_epochs=8,\n",
        "    target_kl=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "NSoQSbmFRZwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_trainer = PPOTrainer(\n",
        "    config= ppo_config,\n",
        "    model=policy_model,\n",
        "    ref_model=ref_model,\n",
        "    tokenizer=tokenizer,\n",
        "    dataset=dataset,\n",
        ")\n",
        "dummy_dataloader = ppo_trainer.dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "q6KBUq04RZ6X",
        "outputId": "690ffd5d-8de8-44da-95ab-a30e5a1b91f8"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-32c8ec93d8d2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m ppo_trainer = PPOTrainer(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mppo_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mref_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, model, ref_model, tokenizer, dataset, optimizer, data_collator, num_shared_layers, lr_scheduler)\u001b[0m\n\u001b[1;32m    188\u001b[0m             )\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSUPPORTED_ARCHITECTURES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    191\u001b[0m                 \u001b[0;34mf\"model must be a PreTrainedModelWrapper, got {type(model)} - supported architectures are: {SUPPORTED_ARCHITECTURES}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: model must be a PreTrainedModelWrapper, got <class 'transformers.models.t5.modeling_t5.T5ForConditionalGeneration'> - supported architectures are: (<class 'trl.models.modeling_value_head.AutoModelForCausalLMWithValueHead'>, <class 'trl.models.modeling_value_head.AutoModelForSeq2SeqLMWithValueHead'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for query_tensor, response_tensor in dummy_dataloader:\n",
        "    # define a reward for response\n",
        "    # (this could be any reward such as human feedback or output from another model)\n",
        "    reward = [torch.tensor(1.0), torch.tensor(0.0)]\n",
        "    # train model\n",
        "    train_stats = ppo_trainer.step([q for q in query_tensor], [r for r in response_tensor], reward)\n",
        "    break"
      ],
      "metadata": {
        "id": "uh_3tsRg08pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    question_tensors = batch[\"input_ids\"]\n",
        "\n",
        "    response_tensors = ppo_trainer.generate(\n",
        "        question_tensors,\n",
        "        return_prompt=False,\n",
        "        length_sampler=output_length_sampler,\n",
        "        **generation_kwargs,\n",
        "    )\n",
        "    batch[\"response\"] = tokenizer.batch_decode(response_tensors, skip_special_tokens=True)\n",
        "\n",
        "    # Compute reward score (using the sentiment analysis pipeline)\n",
        "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
        "    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n",
        "    rewards = [torch.tensor(output[0][\"score\"] - script_args.reward_baseline) for output in pipe_outputs]"
      ],
      "metadata": {
        "id": "a_Miqn5Cwowt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
        "    if epoch >= config.total_ppo_epochs:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "kJRwSOBFuNRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run PPO step\n",
        "stats = ppo_trainer.step(question_tensors, response_tensors, rewards)"
      ],
      "metadata": {
        "id": "ahL0nSvTRaGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log stats to Wandb\n",
        "ppo_trainer.log_stats(stats, batch, rewards)"
      ],
      "metadata": {
        "id": "HA5x1tKRZA7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgDlnYbAqyIY",
        "outputId": "4a28dcdd-ef2f-4050-f802-a3aa3b9b11f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"./rewards_model/\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./rewards_model/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "56SFQ-42t2-t",
        "outputId": "57d96da5-1da0-4200-e713-a693269ccd4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a4d597d257d9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./rewards_model/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./rewards_model/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AutoModelForSequenceClassification' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bZay7a6yxMP9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}