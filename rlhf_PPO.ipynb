{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/PanoEvJ/summarization_RLHF/blob/main/rlhf_PPO.ipynb",
      "authorship_tag": "ABX9TyMoWCtmIP7FP4vMez24M5Zv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f7b877d08c094d1db89b8a7da139683a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d51bc390cc344b8ac29daee4394c0c2",
              "IPY_MODEL_ef1b17ba9ffe42f785ff93231535e78d",
              "IPY_MODEL_4ae5b64a3b10449098cce3828a01a0a4"
            ],
            "layout": "IPY_MODEL_6fc4ef73ba13418bba2e526022b0ddb2"
          }
        },
        "0d51bc390cc344b8ac29daee4394c0c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1814ccf42f13466bbcbb339c7c174b5c",
            "placeholder": "​",
            "style": "IPY_MODEL_22084dfa150e4995a25879b13a0bf6c1",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ef1b17ba9ffe42f785ff93231535e78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06e45decaffa4d77901d04b76052c545",
            "max": 1476,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d714221a643478096553d9e0814c022",
            "value": 1476
          }
        },
        "4ae5b64a3b10449098cce3828a01a0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ad5c2de43d042fe84da1846b4fe2ed9",
            "placeholder": "​",
            "style": "IPY_MODEL_18e15ca601c141a090d5240be53a0edb",
            "value": " 1.48k/1.48k [00:00&lt;00:00, 117kB/s]"
          }
        },
        "6fc4ef73ba13418bba2e526022b0ddb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1814ccf42f13466bbcbb339c7c174b5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22084dfa150e4995a25879b13a0bf6c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06e45decaffa4d77901d04b76052c545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d714221a643478096553d9e0814c022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ad5c2de43d042fe84da1846b4fe2ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e15ca601c141a090d5240be53a0edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cf1c6ba819c4b32a2bc36c1ba9583b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6abc8096b43349d8a32e79262b51825d",
              "IPY_MODEL_a7005a5625504794ab6eaa7c279eaa3a",
              "IPY_MODEL_6cd2161b55584a739fa31ccb071c9bf9"
            ],
            "layout": "IPY_MODEL_00c83ad08fa545aca5d3513ed3bebe53"
          }
        },
        "6abc8096b43349d8a32e79262b51825d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_645b6c220b2d462d8c45df23e1a2ceef",
            "placeholder": "​",
            "style": "IPY_MODEL_9d6eeaf1523d4775860a7701facd29f0",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "a7005a5625504794ab6eaa7c279eaa3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3795adc38434734b47320c7e964fc48",
            "max": 891702929,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b1cab68d5164e6bbcb1bfcdc87ca943",
            "value": 891702929
          }
        },
        "6cd2161b55584a739fa31ccb071c9bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d059d0b92c0949b0946f7742b90a2ef0",
            "placeholder": "​",
            "style": "IPY_MODEL_5d3b71ba2d474ffdb70124adc49d29f9",
            "value": " 892M/892M [00:02&lt;00:00, 416MB/s]"
          }
        },
        "00c83ad08fa545aca5d3513ed3bebe53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "645b6c220b2d462d8c45df23e1a2ceef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d6eeaf1523d4775860a7701facd29f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3795adc38434734b47320c7e964fc48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b1cab68d5164e6bbcb1bfcdc87ca943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d059d0b92c0949b0946f7742b90a2ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d3b71ba2d474ffdb70124adc49d29f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf3d89bd505b4349bfe760e2fc269148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dfcffd57a7e43a491f1f3cbc8430454",
              "IPY_MODEL_49087ea0d75c4f28a395c270f6141116",
              "IPY_MODEL_6236d5d849a34feeb2e8e369e563997c"
            ],
            "layout": "IPY_MODEL_9921b3e8390f41d2b5e09179b89ee9e9"
          }
        },
        "7dfcffd57a7e43a491f1f3cbc8430454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_605de86e238643f88ddf00ff9e300c16",
            "placeholder": "​",
            "style": "IPY_MODEL_8dbbb2d5b2984b17ac5205e815e8e839",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "49087ea0d75c4f28a395c270f6141116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_343ed583db04401aa5fe501a6b7f83df",
            "max": 142,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7f4996f1e4445dcaa84b1bd483c27f7",
            "value": 142
          }
        },
        "6236d5d849a34feeb2e8e369e563997c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecd8fd77e1844dcd8e54afa67db937e1",
            "placeholder": "​",
            "style": "IPY_MODEL_34115d72c2b94336b805c2a61993831f",
            "value": " 142/142 [00:00&lt;00:00, 12.9kB/s]"
          }
        },
        "9921b3e8390f41d2b5e09179b89ee9e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "605de86e238643f88ddf00ff9e300c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dbbb2d5b2984b17ac5205e815e8e839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "343ed583db04401aa5fe501a6b7f83df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7f4996f1e4445dcaa84b1bd483c27f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecd8fd77e1844dcd8e54afa67db937e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34115d72c2b94336b805c2a61993831f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "726f3dfb8899410d8a4c2392ecce9106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e14b2ec027d45eba070dbb6a7de6425",
              "IPY_MODEL_49ce253d4b134f019d4da4fce1b0dea9",
              "IPY_MODEL_48de5c5238f14ae19308d1b0fec7e4e3"
            ],
            "layout": "IPY_MODEL_2ed9595b244b425ca6b273ba09f2e8b2"
          }
        },
        "3e14b2ec027d45eba070dbb6a7de6425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58302403c4ba466da1f7c3dcc24e0b3f",
            "placeholder": "​",
            "style": "IPY_MODEL_1f47da38dda2417180d1dfdd803780d7",
            "value": "Downloading spiece.model: 100%"
          }
        },
        "49ce253d4b134f019d4da4fce1b0dea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c735608ec0e45d08d3cd36fac175b6a",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_847ac529db5c44aabba4a00e6737747e",
            "value": 791656
          }
        },
        "48de5c5238f14ae19308d1b0fec7e4e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_010ed0c0559b4685810d688b8a1705dd",
            "placeholder": "​",
            "style": "IPY_MODEL_e5a7fef181fd4504be9eaa1527dd0a10",
            "value": " 792k/792k [00:00&lt;00:00, 58.9MB/s]"
          }
        },
        "2ed9595b244b425ca6b273ba09f2e8b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58302403c4ba466da1f7c3dcc24e0b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f47da38dda2417180d1dfdd803780d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c735608ec0e45d08d3cd36fac175b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "847ac529db5c44aabba4a00e6737747e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "010ed0c0559b4685810d688b8a1705dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a7fef181fd4504be9eaa1527dd0a10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "400eb25bdeab41e7be6493762780e935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7551d02057e24022a6977e4617048d44",
              "IPY_MODEL_a368b9620eee4d27a0cdd353176c919f",
              "IPY_MODEL_93e238e7221348fdab195c4e674073d5"
            ],
            "layout": "IPY_MODEL_571d084c7c5448e6927820dbdd452af1"
          }
        },
        "7551d02057e24022a6977e4617048d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b03472d3074c4dd58b3e88272a93ad4f",
            "placeholder": "​",
            "style": "IPY_MODEL_6c6da115e3fd47c7ab08678df6ceba55",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "a368b9620eee4d27a0cdd353176c919f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8582bb6a506b4c47a1f8f76bc8c175f0",
            "max": 2200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e098af9c3eef4417b22c5d8a70b59062",
            "value": 2200
          }
        },
        "93e238e7221348fdab195c4e674073d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d5ccd932f524399b70a4fa870cd07bc",
            "placeholder": "​",
            "style": "IPY_MODEL_ed1d0c0d11b4404cacbb467f7b0f1bde",
            "value": " 2.20k/2.20k [00:00&lt;00:00, 204kB/s]"
          }
        },
        "571d084c7c5448e6927820dbdd452af1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b03472d3074c4dd58b3e88272a93ad4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c6da115e3fd47c7ab08678df6ceba55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8582bb6a506b4c47a1f8f76bc8c175f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e098af9c3eef4417b22c5d8a70b59062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d5ccd932f524399b70a4fa870cd07bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed1d0c0d11b4404cacbb467f7b0f1bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5de5e811ba0041e798fd2a506c60fe8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_344ea8479adf4b529c166fd7b37c1afa",
              "IPY_MODEL_91c40378f3334eeab94e8de6ec51da96",
              "IPY_MODEL_e950fb54c34a4fc089666d37834c7b6e"
            ],
            "layout": "IPY_MODEL_7178922542f54e32af19401662ac31a1"
          }
        },
        "344ea8479adf4b529c166fd7b37c1afa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98782de26f8641be811c5558d112805f",
            "placeholder": "​",
            "style": "IPY_MODEL_1c31001822df4ea78e653ff4af32dd98",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "91c40378f3334eeab94e8de6ec51da96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_774b4214644e47b397681e9983e02247",
            "max": 2365,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_822e132c929a431da6246faffaa1445e",
            "value": 2365
          }
        },
        "e950fb54c34a4fc089666d37834c7b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a4fe2f53f3d44f79e03dcbe8c381b43",
            "placeholder": "​",
            "style": "IPY_MODEL_4c602be748b44d76addff8e587eb2322",
            "value": " 2.37k/2.37k [00:00&lt;00:00, 221kB/s]"
          }
        },
        "7178922542f54e32af19401662ac31a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98782de26f8641be811c5558d112805f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c31001822df4ea78e653ff4af32dd98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "774b4214644e47b397681e9983e02247": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "822e132c929a431da6246faffaa1445e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a4fe2f53f3d44f79e03dcbe8c381b43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c602be748b44d76addff8e587eb2322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02bc45bf617c4922811d373413ae7f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5d2cba4363c4f4fbfeafcfe96f53dff",
              "IPY_MODEL_8b6963a81ab4482d8b380ba98485d278",
              "IPY_MODEL_9bb472ee94354fdfad0069665fa5b848"
            ],
            "layout": "IPY_MODEL_fa24e15f42244d5aaeaa25aee6d0792b"
          }
        },
        "a5d2cba4363c4f4fbfeafcfe96f53dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_378a9df0f1e142b6b3545e71656c5d78",
            "placeholder": "​",
            "style": "IPY_MODEL_6d2c7a0747a448c6bfdeb1b23c3259a8",
            "value": "Map: 100%"
          }
        },
        "8b6963a81ab4482d8b380ba98485d278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbd37fa7c34843e3a342421460f4cc99",
            "max": 6000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7286037cf8044ca4a0638c8f83e09e60",
            "value": 6000
          }
        },
        "9bb472ee94354fdfad0069665fa5b848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad9fba374cc3458ea2aa1a0bb2e3a126",
            "placeholder": "​",
            "style": "IPY_MODEL_72574bc5b8c44d90a8c1b78aa9a6a02f",
            "value": " 6000/6000 [00:11&lt;00:00, 531.78 examples/s]"
          }
        },
        "fa24e15f42244d5aaeaa25aee6d0792b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "378a9df0f1e142b6b3545e71656c5d78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d2c7a0747a448c6bfdeb1b23c3259a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbd37fa7c34843e3a342421460f4cc99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7286037cf8044ca4a0638c8f83e09e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad9fba374cc3458ea2aa1a0bb2e3a126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72574bc5b8c44d90a8c1b78aa9a6a02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76c2e5caadf84a64b4237b87cf260e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c683a7230f1e4db98385af0ecdb47eab",
              "IPY_MODEL_330f80ca99be4e67bbe12accec63b815",
              "IPY_MODEL_77ced790fd5046e7978ef3e060029797"
            ],
            "layout": "IPY_MODEL_c8898f33efd747598f3e3e649a9ac281"
          }
        },
        "c683a7230f1e4db98385af0ecdb47eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e44e4f0fcc845408ce2c7e9ee407ffb",
            "placeholder": "​",
            "style": "IPY_MODEL_b0f50fa1968345168d3c5221ca767f70",
            "value": "Map: 100%"
          }
        },
        "330f80ca99be4e67bbe12accec63b815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_731c8bb24e1c4bce9db1de8a8a5cdcb1",
            "max": 24000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_013dfb0cbd13445bae65f6f310fa08b1",
            "value": 24000
          }
        },
        "77ced790fd5046e7978ef3e060029797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_063fe1edbd094a19b19efdfdacd667c5",
            "placeholder": "​",
            "style": "IPY_MODEL_d7fd7270b18943a8b66b391530d1f0d1",
            "value": " 24000/24000 [00:45&lt;00:00, 542.85 examples/s]"
          }
        },
        "c8898f33efd747598f3e3e649a9ac281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e44e4f0fcc845408ce2c7e9ee407ffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f50fa1968345168d3c5221ca767f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "731c8bb24e1c4bce9db1de8a8a5cdcb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "013dfb0cbd13445bae65f6f310fa08b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "063fe1edbd094a19b19efdfdacd667c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7fd7270b18943a8b66b391530d1f0d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PanoEvJ/summarization_RLHF/blob/main/rlhf_PPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "id": "bZay7a6yxMP9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b2a78f6-d46a-44b6-b7ea-81359cb8bee3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AguXQuvcFKvF",
        "outputId": "64350d6c-025e-43c2-916a-b522af248f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for trl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.8/188.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.8/218.8 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U git+https://github.com/lvwerra/trl.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "\n",
        "!pip install -q transformers==4.30\n",
        "!pip install -q -U sentencepiece\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -q tdqm torch>=0.3.0\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import wandb\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset as TorchDataset\n",
        "from datasets import load_dataset, Dataset as HFDataset\n",
        "from peft import (AutoPeftModelForCausalLM,\n",
        "                  LoraConfig,\n",
        "                  PeftConfig,\n",
        "                  PeftModel,\n",
        "                  TaskType,\n",
        "                  get_peft_config,\n",
        "                  get_peft_model,\n",
        "                  get_peft_model_state_dict,\n",
        "                  set_peft_model_state_dict,\n",
        "                  PeftType,\n",
        ")\n",
        "from tqdm import tqdm\n",
        "from transformers import (AutoModelForSeq2SeqLM,\n",
        "                          AutoModelForSequenceClassification,\n",
        "                          AutoTokenizer,\n",
        "                          BitsAndBytesConfig,\n",
        "                          TrainingArguments,\n",
        "                          AutoTokenizer,\n",
        "                          T5ForConditionalGeneration,\n",
        "                          T5Tokenizer\n",
        ")\n",
        "from trl import (SFTTrainer,\n",
        "                 PPOConfig,\n",
        "                 PPOTrainer,\n",
        "                 AutoModelForSeq2SeqLMWithValueHead,\n",
        "                 create_reference_model,\n",
        "                 set_seed\n",
        ")\n",
        "from trl.core import LengthSampler"
      ],
      "metadata": {
        "id": "Mo3XpkZaFSfj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Cuda"
      ],
      "metadata": {
        "id": "wIa1CPYWR-zD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "YhhnxnJXR9Mb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Rewards Model from Google Drive"
      ],
      "metadata": {
        "id": "kc9E_Oj5KOSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rewards_model_directory = \"./gdrive/MyDrive/rewards_model/\"\n",
        "\n",
        "rm_model = AutoModelForSequenceClassification.from_pretrained(rewards_model_directory)\n",
        "rm_tokenizer = AutoTokenizer.from_pretrained(rewards_model_directory)\n",
        "rm_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDoJ-lOVqyU0",
        "outputId": "7e0a231f-38e6-4c43-c5ed-4e491b763744"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ./gdrive/MyDrive/rewards_model/ were not used when initializing BertForSequenceClassification: ['bert.encoder.layer.1.attention.self.value.lora_B.default.weight', 'bert.encoder.layer.5.attention.self.value.lora_A.default.weight', 'bert.encoder.layer.0.attention.self.query.lora_B.default.weight', 'bert.encoder.layer.10.attention.self.value.lora_A.default.weight', 'bert.encoder.layer.4.attention.self.query.lora_A.default.weight', 'bert.encoder.layer.8.attention.self.value.lora_B.default.weight', 'bert.encoder.layer.11.attention.self.query.lora_B.default.weight', 'bert.encoder.layer.10.attention.self.query.lora_B.default.weight', 'bert.encoder.layer.3.attention.self.query.lora_A.default.weight', 'bert.encoder.layer.6.attention.self.query.lora_B.default.weight', 'bert.encoder.layer.8.attention.self.value.lora_A.default.weight', 'bert.encoder.layer.8.attention.self.query.lora_A.default.weight', 'bert.encoder.layer.8.attention.self.query.lora_B.default.weight', 'bert.encoder.layer.4.attention.self.query.lora_B.default.weight', 'bert.encoder.layer.1.attention.self.value.lora_A.default.weight', 'classifier.original_module.weight', 'bert.encoder.layer.11.attention.self.value.lora_B.default.weight', 'bert.encoder.layer.6.attention.self.value.lora_B.default.weight', 'classifier.original_module.bias', 'bert.encoder.layer.9.attention.self.value.lora_B.default.weight', 'classifier.modules_to_save.default.weight', 'bert.encoder.layer.0.attention.self.query.lora_A.default.weight', 'bert.encoder.layer.1.attention.self.query.lora_B.default.weight', 'bert.encoder.layer.3.attention.self.value.lora_B.default.weight', 'bert.encoder.layer.1.attention.self.query.lora_A.default.weight', 'bert.encoder.layer.4.attention.self.value.lora_B.default.weight', 'bert.encoder.layer.5.attention.self.query.lora_A.default.weight', 'bert.encoder.layer.6.attention.self.value.lora_A.default.weight', 'bert.encoder.layer.7.attention.self.value.lora_A.default.weight', 'bert.encoder.layer.4.attention.self.value.lora_A.default.weight', 'bert.encoder.layer.10.attention.self.value.lora_B.default.weight', 'bert.encoder.layer.5.attention.self.query.lora_B.default.weight', 'bert.encoder.layer.9.attention.self.query.lora_A.default.weight', 'bert.encoder.layer.11.attention.self.value.lora_A.default.weight', 'bert.encoder.layer.3.attention.self.query.lora_B.default.weight', 'bert.encoder.layer.2.attention.self.query.lora_A.default.weight', 'bert.encoder.layer.2.attention.self.query.lora_B.default.weight', 'bert.encoder.layer.9.attention.self.value.lora_A.default.weight', 'bert.encoder.layer.0.attention.self.value.lora_B.default.weight', 'bert.encoder.layer.10.attention.self.query.lora_A.default.weight', 'bert.encoder.layer.9.attention.self.query.lora_B.default.weight', 'bert.encoder.layer.11.attention.self.query.lora_A.default.weight', 'bert.encoder.layer.5.attention.self.value.lora_B.default.weight', 'bert.encoder.layer.2.attention.self.value.lora_B.default.weight', 'bert.encoder.layer.3.attention.self.value.lora_A.default.weight', 'bert.encoder.layer.2.attention.self.value.lora_A.default.weight', 'bert.encoder.layer.7.attention.self.value.lora_B.default.weight', 'bert.encoder.layer.7.attention.self.query.lora_B.default.weight', 'bert.encoder.layer.6.attention.self.query.lora_A.default.weight', 'bert.encoder.layer.7.attention.self.query.lora_A.default.weight', 'classifier.modules_to_save.default.bias', 'bert.encoder.layer.0.attention.self.value.lora_A.default.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./gdrive/MyDrive/rewards_model/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def score_summaries(model, tokenizer, chosen_summary, rejected_summary):\n",
        "    # Tokenize the inputs\n",
        "    chosen_tokens = tokenizer(chosen_summary, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
        "    rejected_tokens = tokenizer(rejected_summary, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
        "\n",
        "    chosen_tokens.to(device)\n",
        "    rejected_tokens.to(device)\n",
        "\n",
        "    # Get logits from the model\n",
        "    with torch.no_grad():\n",
        "        chosen_logits = model(**chosen_tokens).logits\n",
        "        rejected_logits = model(**rejected_tokens).logits\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    chosen_probs = F.softmax(chosen_logits, dim=-1)\n",
        "    rejected_probs = F.softmax(rejected_logits, dim=-1)\n",
        "\n",
        "    # Assuming the positive class (indicating 'chosen' is good) is the second one\n",
        "    chosen_score = chosen_probs[0][1].item()\n",
        "    rejected_score = rejected_probs[0][1].item()\n",
        "\n",
        "    # Extract logits for each summary\n",
        "    chosen_logit = chosen_logits[0][1].item()\n",
        "    rejected_logit = rejected_logits[0][1].item()\n",
        "\n",
        "    return chosen_score, rejected_score, chosen_logit, rejected_logit"
      ],
      "metadata": {
        "id": "AIvmuEbjTEb_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chosen_summary = \"Water meter in another condo is not in our condo. What can we do legally to restore water to my condo complex?\"\n",
        "rejected_summary = \"Go fix the problem.\""
      ],
      "metadata": {
        "id": "5YMOOuipTTKk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chosen_score, rejected_score, chosen_logit, rejected_logit = score_summaries(rm_model, rm_tokenizer, chosen_summary, rejected_summary)\n",
        "\n",
        "print(f\"Chosen Score: {chosen_score:.4f}\")\n",
        "print(f\"Rejected Score: {rejected_score:.4f}\")\n",
        "\n",
        "print(f\"Chosen Logit: {chosen_logit:.4f}\")\n",
        "print(f\"Rejected Logit: {rejected_logit:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcQe8PKBTW7x",
        "outputId": "446994ca-53dd-4e23-cbde-d719fb474ac3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen Score: 0.3314\n",
            "Rejected Score: 0.4517\n",
            "Chosen Logit: -0.6432\n",
            "Rejected Logit: -0.4931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the T5 model"
      ],
      "metadata": {
        "id": "9wF8PcPzTndh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy_model_name = \"t5-base\"\n",
        "policy_model_id = 'PanoEvJ/T5_base_SFT_summarization'"
      ],
      "metadata": {
        "id": "8BBUjvjkTyDk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_8bit=True,\n",
        "#     bnb_8bit_use_double_quant=True,\n",
        "#     bnb_8bit_quant_type=\"nf8\",\n",
        "#     bnb_8bit_compute_dtype=torch.bfloat16,\n",
        "# )"
      ],
      "metadata": {
        "id": "QUI2BjQ-Isoy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy_model = T5ForConditionalGeneration.from_pretrained(policy_model_id)\n",
        "policy_model.to(device)\n",
        "policy_tokenizer = T5Tokenizer.from_pretrained(policy_model_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "f7b877d08c094d1db89b8a7da139683a",
            "0d51bc390cc344b8ac29daee4394c0c2",
            "ef1b17ba9ffe42f785ff93231535e78d",
            "4ae5b64a3b10449098cce3828a01a0a4",
            "6fc4ef73ba13418bba2e526022b0ddb2",
            "1814ccf42f13466bbcbb339c7c174b5c",
            "22084dfa150e4995a25879b13a0bf6c1",
            "06e45decaffa4d77901d04b76052c545",
            "5d714221a643478096553d9e0814c022",
            "9ad5c2de43d042fe84da1846b4fe2ed9",
            "18e15ca601c141a090d5240be53a0edb",
            "5cf1c6ba819c4b32a2bc36c1ba9583b5",
            "6abc8096b43349d8a32e79262b51825d",
            "a7005a5625504794ab6eaa7c279eaa3a",
            "6cd2161b55584a739fa31ccb071c9bf9",
            "00c83ad08fa545aca5d3513ed3bebe53",
            "645b6c220b2d462d8c45df23e1a2ceef",
            "9d6eeaf1523d4775860a7701facd29f0",
            "c3795adc38434734b47320c7e964fc48",
            "6b1cab68d5164e6bbcb1bfcdc87ca943",
            "d059d0b92c0949b0946f7742b90a2ef0",
            "5d3b71ba2d474ffdb70124adc49d29f9",
            "cf3d89bd505b4349bfe760e2fc269148",
            "7dfcffd57a7e43a491f1f3cbc8430454",
            "49087ea0d75c4f28a395c270f6141116",
            "6236d5d849a34feeb2e8e369e563997c",
            "9921b3e8390f41d2b5e09179b89ee9e9",
            "605de86e238643f88ddf00ff9e300c16",
            "8dbbb2d5b2984b17ac5205e815e8e839",
            "343ed583db04401aa5fe501a6b7f83df",
            "c7f4996f1e4445dcaa84b1bd483c27f7",
            "ecd8fd77e1844dcd8e54afa67db937e1",
            "34115d72c2b94336b805c2a61993831f",
            "726f3dfb8899410d8a4c2392ecce9106",
            "3e14b2ec027d45eba070dbb6a7de6425",
            "49ce253d4b134f019d4da4fce1b0dea9",
            "48de5c5238f14ae19308d1b0fec7e4e3",
            "2ed9595b244b425ca6b273ba09f2e8b2",
            "58302403c4ba466da1f7c3dcc24e0b3f",
            "1f47da38dda2417180d1dfdd803780d7",
            "8c735608ec0e45d08d3cd36fac175b6a",
            "847ac529db5c44aabba4a00e6737747e",
            "010ed0c0559b4685810d688b8a1705dd",
            "e5a7fef181fd4504be9eaa1527dd0a10",
            "400eb25bdeab41e7be6493762780e935",
            "7551d02057e24022a6977e4617048d44",
            "a368b9620eee4d27a0cdd353176c919f",
            "93e238e7221348fdab195c4e674073d5",
            "571d084c7c5448e6927820dbdd452af1",
            "b03472d3074c4dd58b3e88272a93ad4f",
            "6c6da115e3fd47c7ab08678df6ceba55",
            "8582bb6a506b4c47a1f8f76bc8c175f0",
            "e098af9c3eef4417b22c5d8a70b59062",
            "1d5ccd932f524399b70a4fa870cd07bc",
            "ed1d0c0d11b4404cacbb467f7b0f1bde",
            "5de5e811ba0041e798fd2a506c60fe8b",
            "344ea8479adf4b529c166fd7b37c1afa",
            "91c40378f3334eeab94e8de6ec51da96",
            "e950fb54c34a4fc089666d37834c7b6e",
            "7178922542f54e32af19401662ac31a1",
            "98782de26f8641be811c5558d112805f",
            "1c31001822df4ea78e653ff4af32dd98",
            "774b4214644e47b397681e9983e02247",
            "822e132c929a431da6246faffaa1445e",
            "2a4fe2f53f3d44f79e03dcbe8c381b43",
            "4c602be748b44d76addff8e587eb2322"
          ]
        },
        "id": "YMvy7UO-T-hQ",
        "outputId": "dc009b36-71ec-4919-e924-8fa119eb4f24"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7b877d08c094d1db89b8a7da139683a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5cf1c6ba819c4b32a2bc36c1ba9583b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf3d89bd505b4349bfe760e2fc269148"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "726f3dfb8899410d8a4c2392ecce9106"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "400eb25bdeab41e7be6493762780e935"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.37k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5de5e811ba0041e798fd2a506c60fe8b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task_prefix = \"summarize: \"\n",
        "\n",
        "text = \"SUBREDDIT: r/relationships TITLE: How do I/do I at all [20 F] tell my boyfriend [23 M] that I'm bisexual? POST: I've had two serious relationships prior to this one, both with women. They had no problem with me being bisexual and it was something known before the relationship -- my first girlfriend was also bisexual. I am now in a relationship with a guy. We've been exclusive for about a month. Having never faced this issue, I come to you, Reddit. Is this something that he needs to know? Is it really relevant to a hetero relationship, regardless of if one of the participants in the relationship is bisexual? If you guys think it is necessary, when do you think is the right time? I think my biggest fear is losing him because of it. I know that I should be with someone who is fine with who I am, but I really like the guy and I'd hate for my sexual orientation to be the thing that kills this.\"\n",
        "#text = \"SUBREDDIT: r/legaladvice TITLE: What can I do legally to restore water to my condominium!? POST: Hi, I live in SE Michigan in a condominium complex. Our water was shut off due to non-payment. (we recieved no notice) and we had to pay all that was due ($1500) We payed this yesterday at 2, they said the water would be turned on immediately. It wasn't. It's now the next day. The lady in our assosciation keeps insisting that the water meter is in another condo. Which we can't access because the person living there is never there (it's being rented) Now we're stuck with no water, no shower, no teeth brushing, no toilets, and no food for certain meals.... Please help us... What can we do? We called the police and they say that we can file a civil report for the lady not doing her job...\"\n",
        "prompt = f\"{task_prefix}{text}\"\n",
        "input_ids = policy_tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "outputs = policy_model.generate(input_ids, max_length=100).to(device)\n",
        "\n",
        "strOutput = policy_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(strOutput)\n",
        "\n",
        "chosen_score, rejected_score, chosen_logit, rejected_logit = score_summaries(rm_model, rm_tokenizer, strOutput, \"\")\n",
        "\n",
        "print(f\"Chosen Score: {chosen_score:.4f}\")\n",
        "print(f\"Rejected Score: {rejected_score:.4f}\")\n",
        "\n",
        "print(f\"Chosen Logit: {chosen_logit:.4f}\")\n",
        "print(f\"Rejected Logit: {rejected_logit:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaGQ1oUoUSkX",
        "outputId": "e46bacc7-39f6-4837-b19d-bdc46d11c41c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1259: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUBREDDIT: r/relationships TITLE: How do I/do I at all [20 F] tell my boyfriend [23 M] that I'm bisexual? POST: I've had two serious relationships prior to this one, both with women. They had no problem with me being bisexual and it was something known before the relationship -- my first girlfriend was also bisexual. I am now in a relationship with a\n",
            "Chosen Score: 0.3509\n",
            "Rejected Score: 0.4677\n",
            "Chosen Logit: -0.5487\n",
            "Rejected Logit: -0.5450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the Peft Adapters"
      ],
      "metadata": {
        "id": "H-WAGkGYWNvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see the available modules by printint out the model\n",
        "print(policy_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OzDbykkTlwn",
        "outputId": "10dc33a2-fb39-4b2f-e022-52676db1da93"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T5ForConditionalGeneration(\n",
            "  (shared): Embedding(32128, 768)\n",
            "  (encoder): T5Stack(\n",
            "    (embed_tokens): Embedding(32128, 768)\n",
            "    (block): ModuleList(\n",
            "      (0): T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (relative_attention_bias): Embedding(32, 12)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseActDense(\n",
            "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
            "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): ReLU()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1-11): 11 x T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseActDense(\n",
            "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
            "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): ReLU()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_layer_norm): T5LayerNorm()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (decoder): T5Stack(\n",
            "    (embed_tokens): Embedding(32128, 768)\n",
            "    (block): ModuleList(\n",
            "      (0): T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (relative_attention_bias): Embedding(32, 12)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerCrossAttention(\n",
            "            (EncDecAttention): T5Attention(\n",
            "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseActDense(\n",
            "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
            "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): ReLU()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1-11): 11 x T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerCrossAttention(\n",
            "            (EncDecAttention): T5Attention(\n",
            "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseActDense(\n",
            "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
            "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): ReLU()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_layer_norm): T5LayerNorm()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=8, # Rank\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.10,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM # T5\n",
        ")"
      ],
      "metadata": {
        "id": "kLL_8LRGR_VB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy_peft_model = get_peft_model(policy_model, lora_config)\n",
        "policy_peft_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lSstke9WRUO",
        "outputId": "52061aba-33bd-4b88-f5b5-b0bdf5a8fdcc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSeq2SeqLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): T5ForConditionalGeneration(\n",
              "      (shared): Embedding(32128, 768)\n",
              "      (encoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 768)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 12)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-11): 11 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (decoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 768)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 12)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-11): 11 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )\n",
        "\n",
        "print_trainable_parameters(policy_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq_wmkUaTR7O",
        "outputId": "55296387-4434-4da3-8ffc-9c9dbac0d292"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 884736 || all params: 223788288 || trainable%: 0.3953450861557152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the Value Head used for the PPOTrainer"
      ],
      "metadata": {
        "id": "KePZYLxPWsfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(policy_peft_model,\n",
        "                                                               torch_dtype=torch.bfloat16,\n",
        "                                                               is_trainable=True)\n",
        "\n",
        "ppo_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQii6BmGQG1w",
        "outputId": "6c43520a-250d-4fc9-d813-99376fdd0ec3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoModelForSeq2SeqLMWithValueHead(\n",
              "  (pretrained_model): PeftModelForSeq2SeqLM(\n",
              "    (base_model): LoraModel(\n",
              "      (model): T5ForConditionalGeneration(\n",
              "        (shared): Embedding(32128, 768)\n",
              "        (encoder): T5Stack(\n",
              "          (embed_tokens): Embedding(32128, 768)\n",
              "          (block): ModuleList(\n",
              "            (0): T5Block(\n",
              "              (layer): ModuleList(\n",
              "                (0): T5LayerSelfAttention(\n",
              "                  (SelfAttention): T5Attention(\n",
              "                    (q): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (v): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (relative_attention_bias): Embedding(32, 12)\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (1): T5LayerFF(\n",
              "                  (DenseReluDense): T5DenseActDense(\n",
              "                    (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                    (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                    (act): ReLU()\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (1-11): 11 x T5Block(\n",
              "              (layer): ModuleList(\n",
              "                (0): T5LayerSelfAttention(\n",
              "                  (SelfAttention): T5Attention(\n",
              "                    (q): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (v): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (1): T5LayerFF(\n",
              "                  (DenseReluDense): T5DenseActDense(\n",
              "                    (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                    (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                    (act): ReLU()\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (final_layer_norm): T5LayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (decoder): T5Stack(\n",
              "          (embed_tokens): Embedding(32128, 768)\n",
              "          (block): ModuleList(\n",
              "            (0): T5Block(\n",
              "              (layer): ModuleList(\n",
              "                (0): T5LayerSelfAttention(\n",
              "                  (SelfAttention): T5Attention(\n",
              "                    (q): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (v): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (relative_attention_bias): Embedding(32, 12)\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (1): T5LayerCrossAttention(\n",
              "                  (EncDecAttention): T5Attention(\n",
              "                    (q): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (v): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (2): T5LayerFF(\n",
              "                  (DenseReluDense): T5DenseActDense(\n",
              "                    (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                    (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                    (act): ReLU()\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (1-11): 11 x T5Block(\n",
              "              (layer): ModuleList(\n",
              "                (0): T5LayerSelfAttention(\n",
              "                  (SelfAttention): T5Attention(\n",
              "                    (q): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (v): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (1): T5LayerCrossAttention(\n",
              "                  (EncDecAttention): T5Attention(\n",
              "                    (q): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (v): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (2): T5LayerFF(\n",
              "                  (DenseReluDense): T5DenseActDense(\n",
              "                    (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                    (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                    (act): ReLU()\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (final_layer_norm): T5LayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (v_head): ValueHead(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (summary): Linear(in_features=768, out_features=1, bias=True)\n",
              "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Reference Model"
      ],
      "metadata": {
        "id": "BDUe5mV5W7uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ref_model = create_reference_model(policy_model)\n",
        "ref_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLJX8AoIW_3U",
        "outputId": "c65f7055-07ed-454b-f366-4a7338bcc97d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Prepare the Dataset"
      ],
      "metadata": {
        "id": "ER92VYh9X0tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "orig_dataset = load_dataset('CarperAI/openai_summarize_comparisons', split='train')\n",
        "\n",
        "# Filter samples where the prompt length is less than or equal to 750\n",
        "filtered_dataset = orig_dataset.filter(lambda example: len(example['prompt'].split()) <= 450) # By word\n",
        "#filtered_dataset = orig_dataset.filter(lambda example: len(example['prompt']) <= 1250) # By character\n",
        "\n",
        "# Shuffle and select the first 10K samples\n",
        "#shuffled_dataset = orig_dataset.shuffle(seed=42).select(range(1000))\n",
        "shuffled_dataset = filtered_dataset.shuffle(seed=42).select(range(1000))\n",
        "\n",
        "\n",
        "# Extract the desired features.  Renaming chose to response to follow the ppo library requirements.\n",
        "new_dataset_dict = {\n",
        "    \"prompt\": shuffled_dataset[\"prompt\"],\n",
        "    \"response\": shuffled_dataset[\"chosen\"]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a new Dataset\n",
        "dataset = HFDataset.from_dict(new_dataset_dict)\n",
        "\n",
        "# Split the new_dataset into train_dataset and eval_dataset\n",
        "# split_ratio = 0.8  # 80% for training, 20% for evaluation\n",
        "dataset_split = dataset.train_test_split(test_size=0.8)\n",
        "train_dataset = dataset_split['train']\n",
        "eval_dataset = dataset_split['test']"
      ],
      "metadata": {
        "id": "1YCnsruXX3dh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0].keys())\n",
        "print(eval_dataset[0].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcoryOEWaFNJ",
        "outputId": "3327748a-ae60-4eda-c4f8-f6322d0fdbc3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['prompt', 'response'])\n",
            "dict_keys(['prompt', 'response'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the dataset"
      ],
      "metadata": {
        "id": "7LW8jCN2aOgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate your tokenizer (replace T5Tokenizer with your model's tokenizer if different)\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\") # or whatever model you're using\n",
        "\n",
        "def tokenize_function(example):\n",
        "    # Tokenize the prompt and store it as input_ids. Also return the response.\n",
        "    return {\n",
        "        \"input_ids\": tokenizer(example[\"prompt\"], return_tensors=\"pt\", truncation=True, max_length=512)[\"input_ids\"].squeeze(),\n",
        "        \"response\": example[\"response\"],\n",
        "    }\n",
        "\n",
        "# Tokenize the training and evaluation datasets\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=False)\n",
        "eval_dataset = eval_dataset.map(tokenize_function, batched=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "02bc45bf617c4922811d373413ae7f78",
            "a5d2cba4363c4f4fbfeafcfe96f53dff",
            "8b6963a81ab4482d8b380ba98485d278",
            "9bb472ee94354fdfad0069665fa5b848",
            "fa24e15f42244d5aaeaa25aee6d0792b",
            "378a9df0f1e142b6b3545e71656c5d78",
            "6d2c7a0747a448c6bfdeb1b23c3259a8",
            "dbd37fa7c34843e3a342421460f4cc99",
            "7286037cf8044ca4a0638c8f83e09e60",
            "ad9fba374cc3458ea2aa1a0bb2e3a126",
            "72574bc5b8c44d90a8c1b78aa9a6a02f",
            "76c2e5caadf84a64b4237b87cf260e0a",
            "c683a7230f1e4db98385af0ecdb47eab",
            "330f80ca99be4e67bbe12accec63b815",
            "77ced790fd5046e7978ef3e060029797",
            "c8898f33efd747598f3e3e649a9ac281",
            "7e44e4f0fcc845408ce2c7e9ee407ffb",
            "b0f50fa1968345168d3c5221ca767f70",
            "731c8bb24e1c4bce9db1de8a8a5cdcb1",
            "013dfb0cbd13445bae65f6f310fa08b1",
            "063fe1edbd094a19b19efdfdacd667c5",
            "d7fd7270b18943a8b66b391530d1f0d1"
          ]
        },
        "id": "0Yl3IfaEGKxK",
        "outputId": "65adbbc0-f6ed-4a9d-9b0a-41893932796b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02bc45bf617c4922811d373413ae7f78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/24000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76c2e5caadf84a64b4237b87cf260e0a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQEcvLS9bq9N",
        "outputId": "832001e2-604b-4b93-a662-1467b86d9c33"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'response', 'input_ids'],\n",
              "    num_rows: 400\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]) # check the input_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lQIhkF7btiE",
        "outputId": "21a7e493-3ff3-4f53-e4e5-4fef5f1f3386"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prompt': \"SUBREDDIT: r/relationships\\nTITLE: I (20F) am very strongly considering doing something potentially horrible. My bf is (22M).\\nPOST: We've been going out for two years, and we've been having a lot of trouble lately. Normally, we're happy as two people can be. But it's been hard.\\n\\nHe has a lying problem. He's had drunk conversations with women, then not told me about them until I went through his phone. I know going through his phone is normally a big no-no, but every time I've done it, I've found something. And he's promised me complete transparency. Still lies, just deletes more texts now.\\n\\nWe had a huge fight, and he apologized about a thousand times. Swore to God he'd never do something like this again. Told me he'd learned his lesson by almost losing me. Said I can have access to anything I want, anytime, even though we've tried that before.\\n\\nSo I gave him a sort-of ultimatum: if he EVER lies to me about something he shouldn't again, I leave him then and there. Now I consider that a sort-of ultimatum because in most relationships, faithfulness is expected.\\n\\n**The Plan:** I want to send a sexy message to him from a fake profile. I mean, I want to make it legit, too. Not obviously fake. Maybe even just start with a normal conversation and see if he'll let it evolve into anything further. I want to see if he's really changed, or if he would at least tell me this time. I want to see if he'd respond, then immediately delete the message. I just need to know his reaction. He's a very handsome dude, and I feel like this exact scenario would happen to him in the future, anyway. So I'd like to know before hand if he'd make the same mistakes again. I know this is testing him, and is probably a bad idea. But I feel like if he passes this test, it'll be the ultimate sign that he's really changed now.\", 'response': \"TL;DR:  I want to send a sexy message to my Bf from a fake profile. I want to see if he'd make the same mistakes he did in the past.\", 'input_ids': [3, 4138, 25582, 11253, 3177, 10, 3, 52, 87, 60, 6105, 2009, 7, 332, 3177, 3765, 10, 27, 17543, 371, 61, 183, 182, 7157, 4014, 692, 424, 6149, 17425, 5, 499, 3, 115, 89, 19, 41, 2884, 329, 137, 276, 14464, 10, 101, 31, 162, 118, 352, 91, 21, 192, 203, 6, 11, 62, 31, 162, 118, 578, 3, 9, 418, 13, 3169, 12643, 5, 3, 23079, 6, 62, 31, 60, 1095, 38, 192, 151, 54, 36, 5, 299, 34, 31, 7, 118, 614, 5, 216, 65, 3, 9, 12267, 682, 5, 216, 31, 7, 141, 18364, 9029, 28, 887, 6, 258, 59, 1219, 140, 81, 135, 552, 27, 877, 190, 112, 951, 5, 27, 214, 352, 190, 112, 951, 19, 4929, 3, 9, 600, 150, 18, 29, 32, 6, 68, 334, 97, 27, 31, 162, 612, 34, 6, 27, 31, 162, 435, 424, 5, 275, 3, 88, 31, 7, 11130, 140, 743, 13567, 5, 4886, 7797, 6, 131, 9268, 7, 72, 14877, 230, 5, 101, 141, 3, 9, 1450, 2870, 6, 11, 3, 88, 22103, 26, 81, 3, 9, 7863, 648, 5, 180, 15295, 12, 601, 3, 88, 31, 26, 470, 103, 424, 114, 48, 541, 5, 332, 1490, 140, 3, 88, 31, 26, 2525, 112, 6114, 57, 966, 5489, 140, 5, 180, 6146, 27, 54, 43, 592, 12, 959, 27, 241, 6, 11008, 6, 237, 713, 62, 31, 162, 1971, 24, 274, 5, 264, 27, 1891, 376, 3, 9, 1843, 18, 858, 11422, 17, 440, 10, 3, 99, 3, 88, 3, 22516, 7797, 12, 140, 81, 424, 3, 88, 6994, 31, 17, 541, 6, 27, 1175, 376, 258, 11, 132, 5, 852, 27, 1099, 24, 3, 9, 1843, 18, 858, 11422, 17, 440, 250, 16, 167, 3079, 6, 13855, 655, 19, 1644, 5, 14011, 634, 2926, 10, 19844, 27, 241, 12, 1299, 3, 9, 3, 7, 994, 63, 1569, 12, 376, 45, 3, 9, 9901, 3278, 5, 27, 1243, 6, 27, 241, 12, 143, 34, 12409, 17, 6, 396, 5, 933, 6865, 9901, 5, 3836, 237, 131, 456, 28, 3, 9, 1389, 3634, 11, 217, 3, 99, 3, 88, 31, 195, 752, 34, 15824, 139, 959, 856, 5, 27, 241, 12, 217, 3, 99, 3, 88, 31, 7, 310, 2130, 6, 42, 3, 99, 3, 88, 133, 44, 709, 817, 140, 48, 97, 5, 27, 241, 12, 217, 3, 99, 3, 88, 31, 26, 3531, 6, 258, 2017, 9268, 8, 1569, 5, 27, 131, 174, 12, 214, 112, 6363, 5, 216, 31, 7, 3, 9, 182, 22989, 146, 221, 6, 11, 27, 473, 114, 48, 2883, 8616, 133, 1837, 12, 376, 16, 8, 647, 6, 6161, 5, 264, 27, 31, 26, 114, 12, 214, 274, 609, 3, 99, 3, 88, 31, 26, 143, 8, 337, 8176, 541, 5, 27, 214, 48, 19, 2505, 376, 6, 11, 19, 1077, 3, 9, 1282, 800, 5, 299, 27, 473, 114, 3, 99, 3, 88, 9016, 48, 794, 6, 34, 31, 195, 36, 8, 5737, 1320, 24, 3, 88, 31, 7, 310, 2130, 230, 5, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PPO Trainer"
      ],
      "metadata": {
        "id": "XMnFJEI0cjt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collator(data):\n",
        "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
        "\n",
        "test_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}, {\"key1\": \"value4\", \"key2\": \"value5\", \"key3\": \"value6\"}]\n",
        "print(f'Collator input: {test_data}')\n",
        "print(f'Collator output: {collator(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOVqDNyYciHQ",
        "outputId": "67d7f396-4b27-44bc-c903-3fa2857be332"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}, {'key1': 'value4', 'key2': 'value5', 'key3': 'value6'}]\n",
            "Collator output: {'key1': ['value1', 'value4'], 'key2': ['value2', 'value5'], 'key3': ['value3', 'value6']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets sample what the collator generates:\n",
        "sample_data = [train_dataset[i] for i in range(3)]  # take first three examples\n",
        "collated_data = collator(sample_data)\n",
        "print(collated_data.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqslXH4scxyX",
        "outputId": "a3ec76f5-1293-4c92-fdba-a5ca8591bc97"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['prompt', 'response', 'input_ids'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_config = PPOConfig(\n",
        "    steps=512,\n",
        "    model_name=policy_model,\n",
        "    learning_rate=1e-4,\n",
        "    batch_size=128,\n",
        "    mini_batch_size=32,\n",
        "    gradient_accumulation_steps=1,\n",
        "    optimize_cuda_cache=True,\n",
        "    ppo_epochs=8,\n",
        "    target_kl=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "NSoQSbmFRZwh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_trainer = PPOTrainer(config=ppo_config,\n",
        "                         model=ppo_model,\n",
        "                         ref_model=ref_model,\n",
        "                         tokenizer=policy_tokenizer,\n",
        "                         dataset=train_dataset,\n",
        "                         data_collator=collator)"
      ],
      "metadata": {
        "id": "q6KBUq04RZ6X"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune the model with PPO\n",
        "\n",
        "The fine-tuning loop consists of the following main steps:\n",
        "\n",
        "Get the query responses from the policy LLM (PEFT model).\n",
        "Get reward from the Rewards model\n",
        "Optimize policy with PPO using the (query, response, reward) triplet."
      ],
      "metadata": {
        "id": "fNYsTz5XdzFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop inspired in the training loop shown by the huggingface examples here:\n",
        "# https://github.com/huggingface/trl/blob/main/trl/trainer/ppo_trainer.py\n",
        "# https://github.com/huggingface/trl/blob/main/tests/test_ppo_trainer.py\n",
        "# https://huggingface.co/docs/trl/using_llama_models\n",
        "# https://github.com/huggingface/trl/blob/main/examples/research_projects/stack_llama/scripts/rl_training.py\n",
        "# https://www.kaggle.com/code/paultimothymooney/fine-tune-flan-t5-with-ppo-deeplearning-ai\n",
        "\n",
        "# This is a HACK... lets see how this works out. May casue bias or may help. The good side is that this, being constant, can effect some type of regularization, preventing the model from gravitating too much towards any specific pattern in the training data.  Just a thought.\n",
        "DEFAULT_REJECTED_SUMMARY_TEXT = \"This is a bad summary\"\n",
        "\n",
        "# Some initial values\n",
        "output_min_length = 100\n",
        "output_max_length = 400\n",
        "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
        "\n",
        "# These hyperparams guide the generation of the completion in the policy model. We could add other params like temperature.\n",
        "generation_kwargs = {\n",
        "    \"temperature\": 0.001,\n",
        "    \"min_length\": 5,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True\n",
        "}\n",
        "\n",
        "max_ppo_steps = 1000\n",
        "ppo_return_mean = []\n",
        "ppo_advantages_mean = []\n",
        "objective_kl = []\n",
        "i = 0\n",
        "\n",
        "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
        "    i += 1\n",
        "    # Break when we reach max_steps.\n",
        "    if step >= max_ppo_steps:\n",
        "        break\n",
        "\n",
        "    prompt_tensors = batch[\"input_ids\"]\n",
        "\n",
        "    # HACK!!!\n",
        "    # Check if original_prompt_tensors is a list of lists\n",
        "    if isinstance(prompt_tensors, list) and all(isinstance(item, list) for item in prompt_tensors):\n",
        "\n",
        "        # Verify if sequences have fixed or variable length\n",
        "        lengths = [len(seq) for seq in prompt_tensors]\n",
        "        unique_lengths = set(lengths)\n",
        "\n",
        "        # If sequences have variable lengths, pad them\n",
        "        if len(unique_lengths) > 1:\n",
        "            max_length = max(unique_lengths)\n",
        "            original_prompt_tensors = [seq + [0] * (max_length - len(seq)) for seq in prompt_tensors]  # padding with zeros\n",
        "\n",
        "        # Convert original_prompt_tensors to individual tensors\n",
        "        prompt_tensors = [torch.tensor(seq).to(device) for seq in prompt_tensors]\n",
        "\n",
        "    summary_tensors = []\n",
        "\n",
        "    for prompt_tensor in prompt_tensors:\n",
        "\n",
        "        prompt_tensor = torch.tensor(prompt_tensor).to(device)\n",
        "\n",
        "        max_new_tokens = output_length_sampler()\n",
        "\n",
        "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
        "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
        "\n",
        "\n",
        "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
        "\n",
        "    #==========================================================================================\n",
        "    batch[\"response\"] = [policy_tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
        "\n",
        "\n",
        "    chosen_summaries = batch[\"response\"]\n",
        "    # Since there are no actual rejected summaries, we use this dummy text.\n",
        "    rejected_summaries = [DEFAULT_REJECTED_SUMMARY_TEXT] * len(batch[\"response\"])\n",
        "\n",
        "    reward_tensors = []\n",
        "\n",
        "    for chosen_summary, rejected_summary in zip(chosen_summaries, rejected_summaries):\n",
        "        chosen_score, _, _, _ = score_summaries(rm_model, rm_tokenizer, chosen_summary, rejected_summary)\n",
        "        reward_tensors.append(torch.tensor(chosen_score))\n",
        "\n",
        "    # ========================================================================================\n",
        "\n",
        "    # https://huggingface.co/docs/trl/trainer#trl.PPOTrainer\n",
        "    # Run PPO step.\n",
        "    # Returns:\n",
        "    #  all_logprobs (torch.FloatTensor): Log probabilities of the responses, shape (batch_size, response_length)\n",
        "    #  all_ref_logprobs (torch.FloatTensor): Log probabilities of the responses, shape (batch_size, response_length)\n",
        "    #  all_values (torch.FloatTensor): Values of the responses, shape (batch_size, response_length)\n",
        "\n",
        "    # From the source code of ppo_trainer.py:\n",
        "        # @PPODecorators.empty_cuda_cache()\n",
        "        # def step(\n",
        "        #     self,\n",
        "        #     queries: List[torch.LongTensor],\n",
        "        #     responses: List[torch.LongTensor],\n",
        "        #     scores: List[torch.FloatTensor],\n",
        "        #     response_masks: Optional[List[torch.LongTensor]] = None,\n",
        "        # ):\n",
        "        #     \"\"\"\n",
        "        #     Run a PPO optimisation step given a list of queries, model responses, and rewards.\n",
        "\n",
        "        #     Args:\n",
        "        #         queries (List[`torch.LongTensor`]):\n",
        "        #             List of tensors containing the encoded queries of shape (`query_length`)\n",
        "        #         responses (List[`torch.LongTensor`]):\n",
        "        #             List of tensors containing the encoded responses of shape (`response_length`)\n",
        "        #         scores (List[`torch.FloatTensor`]):\n",
        "        #             List of tensors containing the scores.\n",
        "        #         response_masks (List[`torch.FloatTensor`], *optional*)):\n",
        "        #             List of tensors containing masks of the response tokens.\n",
        "\n",
        "        #     Returns:\n",
        "        #         `dict[str, Any]`: A summary of the training statistics\n",
        "\n",
        "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
        "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
        "\n",
        "\n",
        "    # https://github.com/huggingface/trl/blob/main/trl/trainer/ppo_trainer.py\n",
        "    # See https://medium.com/@ben.burtenshaw/using-transformer-reinforcement-learning-to-detoxify-generative-language-models-5198446d6786\n",
        "\n",
        "    # From source code of ppo_trainer.py:\n",
        "        # stats = self.record_step_stats(\n",
        "        #     scores=scores,\n",
        "        #     logprobs=all_logprobs,\n",
        "        #     ref_logprobs=ref_logprobs,\n",
        "        #     non_score_reward=non_score_reward,\n",
        "        #     train_stats=train_stats,\n",
        "        #     kl_coef=self.kl_ctl.value,\n",
        "        #     masks=masks,\n",
        "        #     queries=queries,\n",
        "        #     responses=responses,\n",
        "        # )\n",
        "\n",
        "        # Gather/Reduce stats from all processes\n",
        "            # if self.is_distributed:\n",
        "            #     stats = self.gather_stats(stats)\n",
        "            # stats = stats_to_np(stats)\n",
        "            # timing[\"time/ppo/calc_stats\"] = time.time() - t\n",
        "            # stats[\"ppo/learning_rate\"] = self.optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "            # # Update the KL control - multiply the batch_size by the number of processes\n",
        "            # self.kl_ctl.update(\n",
        "            #     stats[\"objective/kl\"],\n",
        "            #     self.config.batch_size * self.accelerator.num_processes,\n",
        "            # )\n",
        "\n",
        "            # # Log the total ppo time\n",
        "            # timing[\"time/ppo/total\"] = time.time() - t0\n",
        "            # stats.update(timing)\n",
        "\n",
        "    print(f'objective/kl: {stats[\"objective/kl\"]}') # Measures how different the policy's action distribution after the update is from the action distribution before the update. PPO tries to make these changes very small to avoid sudden changes.\n",
        "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}') # This is the average return achieved by the agent. Higher is better.\n",
        "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}') # Measures how much better an action is than the average action at a given state.\n",
        "    print('-'.join('' for x in range(100)))\n",
        "\n",
        "    ppo_return_mean.append(stats[\"objective/kl\"])\n",
        "    ppo_advantages_mean.append(stats[\"ppo/returns/mean\"])\n",
        "    objective_kl.append(stats[\"ppo/policy/advantages_mean\"])\n",
        "    if i % 100 == 0: print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh_3tsRg08pt",
        "outputId": "919cb554-9015-4b6a-ec36-ae2c4c446448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]<ipython-input-37-98dcc2c1d616>:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  prompt_tensor = torch.tensor(prompt_tensor).to(device)\n",
            "1it [15:53, 953.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 0.3723834753036499\n",
            "ppo/returns/mean: 0.13576817512512207\n",
            "ppo/policy/advantages_mean: 0.0024852422066032887\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -1.30 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "2it [32:15, 970.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -1.295745849609375\n",
            "ppo/returns/mean: 0.1745375692844391\n",
            "ppo/policy/advantages_mean: -0.001484679407440126\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [48:12, 964.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 0.7359623908996582\n",
            "ppo/returns/mean: 0.17785562574863434\n",
            "ppo/policy/advantages_mean: 0.005121312104165554\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -1.23 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "4it [1:04:02, 958.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -1.2297945022583008\n",
            "ppo/returns/mean: 0.21289286017417908\n",
            "ppo/policy/advantages_mean: -0.003823764156550169\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r5it [1:20:45, 974.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 0.24700230360031128\n",
            "ppo/returns/mean: 0.20613285899162292\n",
            "ppo/policy/advantages_mean: 0.003903705393895507\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -2.12 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "6it [1:36:42, 968.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -2.1166563034057617\n",
            "ppo/returns/mean: 0.253979355096817\n",
            "ppo/policy/advantages_mean: -0.0018147319788113236\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r7it [1:52:54, 969.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 0.10572353005409241\n",
            "ppo/returns/mean: 0.251399427652359\n",
            "ppo/policy/advantages_mean: 0.0013896520249545574\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -3.18 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "8it [2:09:07, 970.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -3.1756744384765625\n",
            "ppo/returns/mean: 0.3160143494606018\n",
            "ppo/policy/advantages_mean: -0.004611494950950146\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r9it [2:24:33, 956.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -0.3314286470413208\n",
            "ppo/returns/mean: 0.31135210394859314\n",
            "ppo/policy/advantages_mean: 0.005699619650840759\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -2.17 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "10it [2:40:52, 963.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -2.1653194427490234\n",
            "ppo/returns/mean: 0.3600289821624756\n",
            "ppo/policy/advantages_mean: -0.002667565830051899\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r11it [2:57:07, 967.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -0.4050205945968628\n",
            "ppo/returns/mean: 0.3538878560066223\n",
            "ppo/policy/advantages_mean: -0.00011758098844438791\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -1.18 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "12it [3:12:45, 958.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -1.1834014654159546\n",
            "ppo/returns/mean: 0.3770902752876282\n",
            "ppo/policy/advantages_mean: -0.0023981670383363962\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r13it [3:28:45, 958.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -0.6954420208930969\n",
            "ppo/returns/mean: 0.3724696934223175\n",
            "ppo/policy/advantages_mean: 0.001843770733103156\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -1.82 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "14it [3:45:02, 964.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -1.8215570449829102\n",
            "ppo/returns/mean: 0.40655744075775146\n",
            "ppo/policy/advantages_mean: -0.001811553374864161\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r15it [4:01:06, 964.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 0.04639515280723572\n",
            "ppo/returns/mean: 0.3850935101509094\n",
            "ppo/policy/advantages_mean: -0.001074744388461113\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -2.40 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "16it [4:17:15, 965.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -2.396578073501587\n",
            "ppo/returns/mean: 0.4231724739074707\n",
            "ppo/policy/advantages_mean: -0.003403628012165427\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r17it [4:33:02, 959.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -0.24415560066699982\n",
            "ppo/returns/mean: 0.4092068076133728\n",
            "ppo/policy/advantages_mean: -0.0015937492717057467\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -2.66 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "18it [4:49:35, 969.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -2.655019998550415\n",
            "ppo/returns/mean: 0.44814345240592957\n",
            "ppo/policy/advantages_mean: -0.002989178989082575\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r19it [5:06:21, 980.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -0.24021665751934052\n",
            "ppo/returns/mean: 0.4353267550468445\n",
            "ppo/policy/advantages_mean: 0.0011440111557021737\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -3.38 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "20it [5:23:18, 991.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -3.3788392543792725\n",
            "ppo/returns/mean: 0.49003782868385315\n",
            "ppo/policy/advantages_mean: -0.004957154393196106\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r21it [5:39:20, 982.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -0.7874483466148376\n",
            "ppo/returns/mean: 0.47934865951538086\n",
            "ppo/policy/advantages_mean: -0.0003009897191077471\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -2.42 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "22it [5:55:10, 972.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -2.4154109954833984\n",
            "ppo/returns/mean: 0.510604202747345\n",
            "ppo/policy/advantages_mean: -0.00491427443921566\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -1.34 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "23it [6:11:23, 973.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -1.3363029956817627\n",
            "ppo/returns/mean: 0.5135699510574341\n",
            "ppo/policy/advantages_mean: 6.20854552835226e-05\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -1.76 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "24it [6:27:25, 969.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -1.7601203918457031\n",
            "ppo/returns/mean: 0.5181953310966492\n",
            "ppo/policy/advantages_mean: -0.0041406163945794106\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -1.60 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "25it [6:43:33, 969.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -1.596524715423584\n",
            "ppo/returns/mean: 0.516312837600708\n",
            "ppo/policy/advantages_mean: -0.002783530857414007\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -2.07 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "26it [7:00:12, 978.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -2.0748000144958496\n",
            "ppo/returns/mean: 0.5359604358673096\n",
            "ppo/policy/advantages_mean: -0.0018555447459220886\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r27it [7:15:26, 958.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -0.8366931676864624\n",
            "ppo/returns/mean: 0.5087354779243469\n",
            "ppo/policy/advantages_mean: -0.0019486964447423816\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1236: UserWarning: KL divergence is starting to become negative: -2.72 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "28it [7:31:48, 965.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: -2.715087413787842\n",
            "ppo/returns/mean: 0.5406967401504517\n",
            "ppo/policy/advantages_mean: -0.005031936801970005\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_return_mean"
      ],
      "metadata": {
        "id": "JlJZ8N0wP-AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_advantages_mean"
      ],
      "metadata": {
        "id": "GZslmcOSQZRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "objective_kl"
      ],
      "metadata": {
        "id": "W945X7LRQd97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import huggingface_hub\n",
        "\n",
        "hf_token = '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'\n",
        "\n",
        "hf_api = huggingface_hub.HfApi(hf_token)"
      ],
      "metadata": {
        "id": "xsDIh3BFI4vV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_trainer.model.push_to_hub('PanoEvJ/T5_PPO_summarization')"
      ],
      "metadata": {
        "id": "9PhRoxlRwJcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JQvWlUzuIRBt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}